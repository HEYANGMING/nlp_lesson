{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验指导"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实验目的：\n",
    "\n",
    "1. 掌握神经网络的基本原理；\n",
    "2. 掌握word2vec的基本原理；\n",
    "3. 掌握Keras的基本用法；\n",
    "4. 掌握tensorflow的基本用法；\n",
    "5. 掌握RNN的基本原理；\n",
    "6. 观察熟悉RNN的两种常见变体(LSTM和GRU)的原理和用法；\n",
    "7. 熟悉深度学习自然语言处理的基本流程。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I 实验描述：\n",
    "\n",
    "#### 数据： 使用爬虫获得的豆瓣评论数据\n",
    "#### 目标： 建立机器学习模型，能够对输入的句子自动判断其对应的分值或感情倾向"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II 数据预处理\n",
    "\n",
    "目的： 将文本信息变成神经网络可以处理的数据格式； "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一部分： 基础理论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III 神经网络的基本原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1: 神经网络的Loss函数的作用为何？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答： 表征预测值与训练集中实际值的差异，作为后续优化的基础。神经网络训练的目标就是求出使得Loss函数最小的参数值。训练的过程就是通过反向传播迭代更新网络参数，从而使得Loss不断减小。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2: 神经网络的激活函数(activation function)起什么作用？ 如果没有激活函数会怎么样？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答：激活函数为神经元提供了非线性的结果输出，如果没有激活函数，就只能表征线性关系，比如纯线性模型就无法解决“异或”这类问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3: 神经网络的softmax如何理解， 其作用是什么？ 在`答案`中写出softmax的python表达；\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答案：softmax就是“柔软的”max，非给出实际的最大值。Softmax实际上是一种概率分布，使得最大的那个概率最大，其余的概率小，所有概率和为1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04201007 0.1141952  0.84379473]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "arr=np.array([2,3,5])\n",
    "softmax_arr=np.exp(arr)/np.sum(np.exp(arr))\n",
    "print(softmax_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4: 简述 normalized_1 和softmax函数的相同点和不同点， 说明softmax相比normalized_1该函数的优势所在\n",
    "```python\n",
    "output = np.array([y1, y2, y3])\n",
    "\n",
    "normalized_1 = output / np.sum(output)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答：L1正则化与Softmax都是正则化的方法，但是L1正则化具有稀疏性，可以用于特征选择。Softmax是logistic回归模型在多分类问题上的推广。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5: 写出crossentropy的函数表达式，说明该函数的作用和意义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答：交叉熵代表两个概率分布之间的差异性。在分类时，一般用Softmax来预测一个样本落在每一类中的概率分布，用one-hot编码代表真实的分类（严格某类为1，其余全是0的概率分布），这样两者的交叉熵就可以作为损失函数，用来衡量预测分类与真实分类label之间的差异大小，在神经网络中通过反向传播不断将其缩小，预测值也就逐渐接近真实值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV 掌握word2vec的基本用法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q6: 说明word2vec要解决的问题背景， 以及word2vec的基本思路， 说明word2vec比起之前方法的优势；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答：对文本中的每一个词，如果用一对一的代码（如one-hot编码）表示，无法衡量词与词之间的语义相似性。Word2Vec通过学习某词作为另一词的临近词的出现概率，认为出现在某词附近概率相近的词的语义是相近的，从而用向量表征这种语义相似性。语义相近的词对应的k维Word2Vec词向量，在k维空间中的距离也是相近的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q7: 说明word2vec的预测目标， predication target, 在答案中写出skip-gram和cbow的预测概率；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答： \n",
    "1.  skip-gram是给定输入单词，预测目标是上下文。\n",
    "$$ \\hat{y}= \\frac{e^{u_{o}^Tv_{c}}}{\\sum_{w=1}^{n}e^{u_{w}^Tv_{c}}} $$\n",
    "$v_{c}$是输入向量，$u_{w}$是所有的分类模型矩阵，$u_{o}$是输出向量的分类模型矩阵。\n",
    "\n",
    "2.  cbow是给定上下文，预测目标是输入单词。\n",
    "$$  h=\\frac{1}{C}W\\sum_{i=1}^{C}x_i $$\n",
    "$$ \\hat{y}= \\frac{e^{u_{o}^Th}}{\\sum_{w=1}^{n}e^{u_{w}^Th}} $$\n",
    "$h$是输入向量，$u_{w}$是所有的分类模型矩阵。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q8: 请说明word2vec的两种常见优化方法，分别阐述其原理；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答：  \n",
    "（1）Hierarchical Softmax  \n",
    "&emsp;&emsp;把之前所有都要计算的从输出softmax层的概率计算变成了一颗二叉霍夫曼树，那么我们的softmax概率计算只需要沿着树形结构进行就可以了。我们可以沿着霍夫曼树从根节点一直走到我们的叶子节点的词。\n",
    "和之前的神经网络语言模型相比，我们的霍夫曼树的所有内部节点就类似之前神经网络隐藏层的神经元,其中，根节点的词向量对应我们的投影后的词向量，而所有叶子节点就类似于之前神经网络softmax输出层的神经元，叶子节点的个数就是词汇表的大小。在霍夫曼树中，隐藏层到输出层的softmax映射不是一下子完成的，而是沿着霍夫曼树一步步完成的，因此这种softmax取名为“Hierarchical Softmax”。  \n",
    "（2）Negative Sampling  \n",
    "&emsp;&emsp;使用Huffman树来代替传统的神经网络，虽然可以提高模型训练的效率，但是如果训练样本里的中心词$w$是一个很生僻的词，那么就得在Huffman树中辛苦的向下走很久了。\n",
    "比如我们有一个训练样本，中心词是$w$,它周围上下文共有$2c$个词，记为$context(w)$。由于这个中心词$w$,的确和$context(w)$相关存在，因此它是一个真实的正例。通过Negative Sampling采样，我们得到$neg$个和$w$不同的中心词$w_{i},i=1,2,..neg$，这样$context(w)$和$w_{i}$就组成了$neg$个并不真实存在的负例。利用这一个正例和$neg$个负例，我们进行二元逻辑回归，得到负采样对应每个词$w_{i}$对应的模型参数$\\theta_{i}$，和每个词的词向量。\n",
    "Negative Sampling这种求解word2vec模型的方法摒弃了Huffman树，采用了负采样的方法来求解。Negative Sampling由于没有采用Huffman树，每次只是通过采样neg个不同的中心词做负例，就可以训练模型，因此整个过程要比Hierarchical Softmax简单。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q9: 请说明word2vec中哈夫曼树的作用；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答：Huffman树可以使得Word2Vec的向量维数降低。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q10: 在gensim中如何实现词向量？ 请将gensim中实现词向量的代码置于`答案`中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答：\n",
    "```python\n",
    "import gensim, logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "sentences = [['first', 'sentence'], ['second', 'sentence']]\n",
    "# train word2vec on the two sentences\n",
    "model = gensim.models.Word2Vec(sentences, min_count=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q11: 请说出除了 skip-gram和cbow的其他4中词向量方法的名字， 并且选取其中两个叙述其基本原理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答：（1）LSA（Latent semantic analysis）  \n",
    "对term-document矩阵（矩阵的每个元素为tf-idf）进行奇异值分解(SVD)，从而得到term的向量表示和document的向量表示。此处使用的TF-IDF主要还是term的全局统计特征。LSA和Word2Vec作为两大类方法的代表，LSA是利用了全局特征的矩阵分解方法，Word2Vec是利用局部上下文的方法。  \n",
    "（2）GloVe  \n",
    "GloVe利用全局统计信息预测词j出现在词i的上下文环境中的概率。GloVe既使用了语料库的全局统计（overall statistics）特征，也使用了局部的上下文特征（即滑动窗口）。为了做到这一点GloVe模型引入了Co-occurrence Probabilities Matrix。  \n",
    "$P_{ij}=P\\left(j\\vert{i}\\right)=\\frac{X_{ij}}{X_i}$  是词$j$出现在词$i$上下文的概率。\n",
    "GloVe认为，这不同的词对应的词向量通过某种函数的作用后所呈现出来的规律和$Ratio=\\frac{P_{ik}}{P_{jk}}$具有一致性，即相等，也就可以认为词向量中包含了共现概率矩阵中的信息。  \n",
    "（3）one-hot  \n",
    "（4）TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V 掌握keras的基本用法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q12. 参考keras参考手册，构建一个机器学习模型，该模型能够完成使用DNN(deep neural networks) 实现MNIST数据集的分类；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答：代码请置于下方：\n",
    "\n",
    "hints:  keras 序列模型构建 https://keras.io/getting-started/sequential-model-guide/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:/Users/trans02/PycharmProjects/untitled1/pycode/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting C:/Users/trans02/PycharmProjects/untitled1/pycode/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting C:/Users/trans02/PycharmProjects/untitled1/pycode/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting C:/Users/trans02/PycharmProjects/untitled1/pycode/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "(55000, 784) (55000, 10)\n",
      "(10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "#先用TensorFlow的方式加载数据集\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist=input_data.read_data_sets('C:/Users/trans02/PycharmProjects/untitled1/pycode/MNIST_data/',one_hot=True)\n",
    "x_train, y_train = mnist.train.images,mnist.train.labels\n",
    "x_test, y_test = mnist.test.images, mnist.test.labels\n",
    "# x_train = x_train.reshape(-1, 28, 28,1).astype('float32')\n",
    "# x_test = x_test.reshape(-1,28, 28,1).astype('float32')\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#建模\n",
    "model = Sequential()\n",
    "# model.add(Dense(512,activation='relu',input_shape=(28*28,)))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(512,activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(10,activation='softmax'))\n",
    "model.add(Dense(10,activation='softmax',input_shape=(28*28,)))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = RMSprop(),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 1s 22us/step - loss: 0.2779 - acc: 0.9222 - val_loss: 0.2737 - val_acc: 0.9239\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 1s 24us/step - loss: 0.2735 - acc: 0.9248 - val_loss: 0.2702 - val_acc: 0.9249\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 2s 29us/step - loss: 0.2701 - acc: 0.9245 - val_loss: 0.2694 - val_acc: 0.9257\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 1s 24us/step - loss: 0.2672 - acc: 0.9267 - val_loss: 0.2689 - val_acc: 0.9259\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 2s 32us/step - loss: 0.2647 - acc: 0.9266 - val_loss: 0.2691 - val_acc: 0.9266\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,y_train,\n",
    "                    batch_size = batch_size,\n",
    "                    epochs = epochs,\n",
    "                    verbose = 1,\n",
    "                    validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:0.269142\n",
      "accuracy:0.926600\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model.evaluate(x_test,y_test,verbose=0)\n",
    "print('loss:%f'%loss+'\\n'+'accuracy:%f'%accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VI 掌握tensorflow的基本用法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q13: 参考tensorflow的参考手册，构建一个机器学习模型，该模型能够完成使用DNN(deep neural networks)实现MNIST数据集的分类；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答：代码请置于下方：\n",
    "\n",
    "hints:tensorflow实现MNIST https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/udacity/2_fullyconnected.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-d8dccf941d65>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From E:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From E:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting C:/Users/trans02/PycharmProjects/untitled1/pycode/MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From E:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting C:/Users/trans02/PycharmProjects/untitled1/pycode/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From E:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting C:/Users/trans02/PycharmProjects/untitled1/pycode/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting C:/Users/trans02/PycharmProjects/untitled1/pycode/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From E:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "input success\n",
      "(55000, 784) (55000, 10)\n",
      "(10000, 784) (10000, 10)\n",
      "(5000, 784) (5000, 10)\n",
      "WARNING:tensorflow:From <ipython-input-13-d8dccf941d65>:26: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "0.9193\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist=input_data.read_data_sets('C:/Users/trans02/PycharmProjects/untitled1/pycode/MNIST_data/',one_hot=True)\n",
    "\n",
    "print('input success')\n",
    "print(mnist.train.images.shape,mnist.train.labels.shape)\n",
    "print(mnist.test.images.shape,mnist.test.labels.shape)\n",
    "print(mnist.validation.images.shape,mnist.validation.labels.shape)\n",
    "\n",
    "import tensorflow as tf\n",
    "sess=tf.InteractiveSession()\n",
    "x=tf.placeholder(tf.float32,[None,784])\n",
    "W=tf.Variable(tf.zeros([784,10]))\n",
    "b=tf.Variable(tf.zeros([10]))\n",
    "y=tf.nn.softmax(tf.matmul(x,W)+b)\n",
    "\n",
    "y_=tf.placeholder(tf.float32,[None,10])\n",
    "cross_entropy=tf.reduce_mean(-tf.reduce_sum(y_*tf.log(y),reduction_indices=[1]))\n",
    "\n",
    "train_step=tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "for i in range(1000):\n",
    "    batch_xs,batch_ys=mnist.train.next_batch(100)\n",
    "    train_step.run({x:batch_xs,y_:batch_ys})\n",
    "\n",
    "correct_prediction=tf.equal(tf.argmax(y,1),tf.arg_max(y_,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "print(accuracy.eval({x:mnist.test.images,y_:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q14: 参考keras和tensorflow对同一问题的实现，说明keras和tensorflow的异同；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答：Tensorflow搭建模型过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q15: Q12， Q13 的tensorflow 或 keras 模型的训练时准确率和测试集准确率分别是多少？\n",
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras只有一层Dense：\n",
    "loss:0.269142\n",
    "accuracy:0.926600\n",
    "\n",
    "TensorFlow只有一层：\n",
    "0.9193"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q16: 训练时准确率大于测试集准确率的现象叫什么名字，在神经网络中如何解决该问题？\n",
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "过拟合。可以通过以下方法减小过拟合：  \n",
    "（1）在神经网络中，如果参数过多，就容易出现过拟合，可以通过简化模型来解决。比如GRU对于LSTM来说就简化了网络结构，减少了参数，因而可以减轻过拟合。  \n",
    "（2）在训练过程中随机丢弃一部分数据，采用dropout的方法也可避免神经网络过度学习训练集的特征。  \n",
    "（3）在每一轮epoch结束后测一下测试集的准确率，如果accuracy不再提升，则停止训练（early stopping）。  \n",
    "（4）在loss函数上附加一个正则化项，可以使得模型参数变得稀疏，从而减轻过拟合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q17: 请使用自己的语言简述通过正则化 (regularization)减小过拟合的原理；\n",
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正则化的一般形式是误差加上一个正则项。特征变量过多会导致过拟合，为了防止过拟合会选择一些比较重要的特征变量，而删掉很多次要的特征变量。但是，如果我们实际上却希望利用到这些特征信息，所以可以添加正则化项来约束这些特征变量，使得这些特征变量的权重很小，接近于0，这样既能保留这些特征变量，又不至于使得这些特征变量的影响过大。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q18: 在tensorflow官方实例中给出的fully connected 神经网络的分类模型中，数据进行了哪些预处理，这些预处理的原因是什么？ \n",
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VII 掌握RNN的基本原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q19: 简述RNN解决的问题所具有的特点；\n",
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN适合处理时间序列相关的问题，比如语音识别、文本理解等。相比于CNN适合空间二维结构的数据处理（图像识别），RNN在NLP中得到了广泛应用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q20: 写出RNN实现时间或者序列相关的数学实现(见课程slides)；\n",
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$h_t=\\sigma_h(W_h\\cdot h_{t-1})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q20: 简述RNN的两种重要变体的提出原因和基本原理？\n",
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "标准的RNN结构中只有一个神经元，一个tanh层进行重复的学习，这样会存在一些弊端。例如，在比较长的环境中，相关的信息和预测的词之间的间隔可以是非常长的，导致RNN 并不能够成功学习到这些知识，LSTM模型就可以解决这一问题。\n",
    "标准LSTM模型是一种特殊的RNN类型，在每一个重复的模块中有四个特殊的结构，以一种特殊的方式进行交互。LSTM模型的核心思想是“细胞状态”。“细胞状态”类似于传送带。直接在整个链上运行，只有一些少量的线性交互。信息在上面流传保持不变会很容易。 LSTM 有通过精心设计的称作为“门”的结构来去除或者增加信息到细胞状态的能力。门是一种让信息选择式通过的方法。他们包含一个 sigmoid 神经网络层和一个 pointwise 乘法操作。  \n",
    "GRU作为LSTM的一种变体，将忘记门和输入门合成了一个单一的更新门。同样还混合了细胞状态和隐藏状态，加诸其他一些改动。最终的模型比标准的 LSTM 模型要简单。LSTM和GRU都能通过各种Gate将重要特征保留，保证其在long-term 传播的时候也不会被丢失。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q21: Attentional RNN 以及 Stacked RNN 和 Bi-RNN 分别是什么，其做了什么改动？\n",
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二部分： 实验过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IIX 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q22：要实现文本分类或情感分类，文本信息需要进行哪些初始化操作？自己手工实现，keras提供的API，tenorflow提供的API，分别是哪些？请提供关键代码置于下边`回答`中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答：\n",
    "\n",
    "1. 简述所需要的初始化操作：\n",
    "2. 自己手工实现的id_to_word, word_to_id, padding, batched等操作如何实现？\n",
    "#    + id_to_word, word_to_id\n",
    "    \n",
    "```python\n",
    "vocab_list=['c','d','a','b']\n",
    "\n",
    "def word_to_id(word,vocab_list):\n",
    "    dic = {}\n",
    "    for k, v in list(enumerate(vocab_list)): dic[k] = v\n",
    "    dic = {v: k for k, v in dic.items()}\n",
    "    return dic[word]\n",
    "\n",
    "def id_to_word(id,vocab_list):\n",
    "    dic = {}\n",
    "    for k, v in list(enumerate(vocab_list)): dic[k] = v\n",
    "    return dic[id]\n",
    "\n",
    "#按id遍历\n",
    "for k in range(len(vocab_list)):print(id_to_word(k,vocab_list))\n",
    "#按word遍历\n",
    "for k in vocab_list:print(word_to_id(k,vocab_list))\n",
    "```\n",
    "\n",
    "# + padding\n",
    "    \n",
    "```python\n",
    "def padding(vector_list,max_length,padding='post',truncating='post'):\n",
    "    for k in range(len(vector_list)):\n",
    "        if len(vector_list[k])<max_length:\n",
    "            if padding=='post' :vector_list[k]+=[0]*(max_length-len(vector_list[k]))#后面补0\n",
    "            elif padding=='pre' :vector_list[k]=[0]*(max_length-len(vector_list[k]))+vector_list[k]#后面补0\n",
    "        elif len(vector_list[k])>max_length:\n",
    "            if truncating=='post' :vector_list[k]=vector_list[k][:max_length]#后面截断\n",
    "            elif truncating=='pre' :vector_list[k]=vector_list[k][(len(vector_list[k])-max_length):]#前面截断\n",
    "    return vector_list\n",
    "\n",
    "vector_list=[[3,4,2,5],[2,3,7],[7,5,9,3,6],[6,5],[2]]\n",
    "print(padding(vector_list,3))\n",
    "vector_list=[[3,4,2,5],[2,3,7],[7,5,9,3,6],[6,5],[2]]\n",
    "print(padding(vector_list,3,padding='pre'))\n",
    "vector_list=[[3,4,2,5],[2,3,7],[7,5,9,3,6],[6,5],[2]]\n",
    "print(padding(vector_list,3,truncating='pre'))\n",
    "vector_list=[[3,4,2,5],[2,3,7],[7,5,9,3,6],[6,5],[2]]\n",
    "print(padding(vector_list,3,padding='pre',truncating='pre'))\n",
    "\n",
    "Output:\n",
    "[[3, 4, 2], [2, 3, 7], [7, 5, 9], [6, 5, 0], [2, 0, 0]]\n",
    "[[3, 4, 2], [2, 3, 7], [7, 5, 9], [0, 6, 5], [0, 0, 2]]\n",
    "[[4, 2, 5], [2, 3, 7], [9, 3, 6], [6, 5, 0], [2, 0, 0]]\n",
    "[[4, 2, 5], [2, 3, 7], [9, 3, 6], [0, 6, 5], [0, 0, 2]]\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "# + batched\n",
    "    \n",
    "```python\n",
    "def get_batches(x,y,batch_size):\n",
    "    truncated_num=len(x)//batch_size * batch_size\n",
    "    x, y = x[:truncated_num], y[:truncated_num]\n",
    "    for batch_index in range(0, len(x), batch_size):\n",
    "        yield x[batch_index:batch_index + batch_size], y[batch_index:batch_index + batch_size]\n",
    "\n",
    "x=[[2,3],[3,5],[6,9],[5,3],[7,5],[5,3],[8,4]]\n",
    "y=[1,0,1,1,0,0,1]\n",
    "\n",
    "for x_batch,y_batch in get_batches(x,y,3):print('x_batch:%s'%x_batch,'y_batch:%s'%y_batch)\n",
    "    \n",
    "Output:\n",
    "x_batch:[[2, 3], [3, 5], [6, 9]] y_batch:[1, 0, 1]\n",
    "x_batch:[[5, 3], [7, 5], [5, 3]] y_batch:[1, 0, 0]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hints: \n",
    "\n",
    "+ 参考1 https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py\n",
    "+ 参考2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IX 构建神经网络模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q22:在没有预训练的词向量时候， keras 如何实现embedding操作，即如何依据一个单词的序列获得其向量表示？\n",
    "回答："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, vector_size, input_length=max_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Q23:在没有预训练的词向量时候， tensorflow 如何实现embedding操作，即如何依据一个单词的序列获得其向量表示？\n",
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q24: 在有预先训练的词向量时候，keras和tensorflow又如何实现embeding操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q25： 基于上文进行的数据预处理，使用keras和tensorflow如何构建神经网络模型？请提供关键代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答： keras模型构建的关键代码："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答：tensorflow模型构建的关键代码："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  X 使用keras的history观察loss以及accuracy的变化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q26: keras如何观察模型的loss变化以及准确率的变化，请列出关键代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答：\n",
    "如果不设置验证集，方法（1）设置validation_split。方法（2）自己输入validation_data: tuple (x_val, y_val) or tuple  (x_val, y_val, val_sample_weights)。画图就会出现acc一直是1，loss一直是0的状况。\n",
    "set the \n",
    "validation_split: Float between 0 and 1. Fraction of the training data to be used as validation data. The model will set apart this fraction of the training data, will not train on it, and will evaluate the loss and any model metrics on this data at the end of each epoch. The validation data is selected from the last samples in the x and y data provided, before shuffling.\n",
    "```python\n",
    "history=model.fit(train_x, train_y, validation_split=0.2,epochs=5, verbose=1)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('value')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['accuracy', 'loss'])\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q27: 请使用matplotlib画出loss变化的趋势；"
   ]
  },
  {
   "attachments": {
    "_auto_0": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答：![_auto_0](attachment:_auto_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XI 使用tensorflow tensorboard观察loss, accuracy的变化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q28: tensorflow如何观察模型的loss变化以及准确率的变化， tensor board 如何使用？ 请列出关键代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q29: 试着点击tensor board的不同按钮 观察图像的变化； 试着给tensorflow board机制 写入不同时候训练的模型时候，给模型取不同的名字，观察tensor board的图像变化；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XII 观察熟悉RNN的两种变体的原理和方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q30:试着改进RNN，使用LSTM， GRU 进行模型的改动， 观察训练结果(loss和accuracy)的变化， 你观察到了什么变化？ 如何解释？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XIII 模型的改进"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q31: 修改vocabulary size, embedding size, 并且结合使用LSTM， GRU， Bi-RNN， Stacked， Attentional, regularization, 等各种方法组合进行模型的优化， 至少进行10次优化，每次优化请按照以下步骤填写："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答：\n",
    "# 见Github代码\n",
    "\n",
    "---这是一个实例----\n",
    "\n",
    "第1次优化：\n",
    "\n",
    "1. 存在的问题： loss下降太慢；\n",
    "2. 准备进行的优化：减小模型的神经单元数量；\n",
    "3. 期待的结果：loss下降加快；\n",
    "4. 实际结果：loss下降的确加快(或者并没有加快)\n",
    "5. 原因分析：模型神经元数量减小，收敛需要的次数减少，loss下降加快\n",
    "\n",
    "\n",
    "---你的实验优化结构记录在此---\n",
    "\n",
    "**第1次优化**：\n",
    "\n",
    "1. 存在的问题： \n",
    "2. 准备进行的优化：\n",
    "3. 期待的结果：\n",
    "4. 实际结果：\n",
    "5. 原因分析：\n",
    "\n",
    "**第2次优化**：\n",
    "\n",
    "1. 存在的问题： \n",
    "2. 准备进行的优化：\n",
    "3. 期待的结果：\n",
    "4. 实际结果：\n",
    "5. 原因分析：\n",
    "\n",
    "**第3次优化**：\n",
    "\n",
    "1. 存在的问题： \n",
    "2. 准备进行的优化：\n",
    "3. 期待的结果：\n",
    "4. 实际结果：\n",
    "5. 原因分析：\n",
    "\n",
    "**第4次优化**：\n",
    "\n",
    "1. 存在的问题： \n",
    "2. 准备进行的优化：\n",
    "3. 期待的结果：\n",
    "4. 实际结果：\n",
    "5. 原因分析：\n",
    "\n",
    "**第5次优化**：\n",
    "\n",
    "1. 存在的问题： \n",
    "2. 准备进行的优化：\n",
    "3. 期待的结果：\n",
    "4. 实际结果：\n",
    "5. 原因分析：\n",
    "\n",
    "**第6次优化**：\n",
    "\n",
    "1. 存在的问题： \n",
    "2. 准备进行的优化：\n",
    "3. 期待的结果：\n",
    "4. 实际结果：\n",
    "5. 原因分析：\n",
    "\n",
    "**第7次优化**：\n",
    "\n",
    "1. 存在的问题： \n",
    "2. 准备进行的优化：\n",
    "3. 期待的结果：\n",
    "4. 实际结果：\n",
    "5. 原因分析：\n",
    "\n",
    "**第9次优化**：\n",
    "\n",
    "1. 存在的问题： \n",
    "2. 准备进行的优化：\n",
    "3. 期待的结果：\n",
    "4. 实际结果：\n",
    "5. 原因分析：\n",
    "\n",
    "**第10次优化**：\n",
    "\n",
    "1. 存在的问题： \n",
    "2. 准备进行的优化：\n",
    "3. 期待的结果：\n",
    "4. 实际结果：\n",
    "5. 原因分析：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XIV问题： 本次实验的总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请写实验的总结报告，描述此次项目的主要过程，其中遇到的问题，以及如何解决这些问题的，以及有什么经验和收获。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
